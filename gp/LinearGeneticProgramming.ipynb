{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25d6f627-c8ba-4a12-bca9-52f6190f56be",
   "metadata": {},
   "source": [
    "# Linear Genetic Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7344a8bd-9374-47d9-bb70-220afa4e68f2",
   "metadata": {},
   "source": [
    "This notebook implements Linear Genetic Programming (LGP) to solve the LunarLander reinforcement learning environment. \n",
    "We'll evolve interpretable control policies that map observations to actions without using complex neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87501286-fa5d-4336-b8e0-fbe4ac34303a",
   "metadata": {},
   "source": [
    "## Introduction to Linear Genetic Programming\n",
    "\n",
    "Linear Genetic Programming (LGP) is a variant of Genetic Programming where programs are represented as sequences of \n",
    "instructions that operate on registers. Each instruction typically follows the format:\n",
    "\n",
    "```\n",
    "r[destination] = r[source1] operation r[source2]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f865cd-c1dc-43cf-90e6-b1ca69471097",
   "metadata": {},
   "source": [
    "Unlike tree-based Genetic Programming where programs are represented as parse trees, LGP uses a linear sequence of \n",
    "instructions, making it more similar to actual computer programs.\n",
    "\n",
    "Benefits of LGP include:\n",
    "- More natural representation for imperative programming constructs\n",
    "- Efficient execution due to sequential processing\n",
    "- Ability to evolve more compact, interpretable solutions\n",
    "- Natural support for information reuse through register values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948934c0-f57b-4418-bcf7-1c3e1eb5b7f3",
   "metadata": {},
   "source": [
    "## Implementation Overview\n",
    "\n",
    "Our implementation consists of several key components:\n",
    "1. The core LGP representation (instructions and programs)\n",
    "2. The evolutionary algorithm framework\n",
    "3. Environment interaction and evaluation\n",
    "4. Visualization and analysis\n",
    "\n",
    "Let's start by importing the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebc7117-d4d4-41a9-a2d9-fef444124225",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Tuple, Dict, Any, Callable\n",
    "import copy\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8df1dd1-31e8-4138-9f32-3651d1f52e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb82620-36ab-4ba6-864b-e7d983d623cb",
   "metadata": {},
   "source": [
    "## 1. LGP Core Representation\n",
    "\n",
    "### 1.1 LGP Instruction\n",
    "\n",
    "The basic building block of our LGP programs is the instruction. Each instruction performs a simple operation\n",
    "on register values and stores the result in a destination register."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb429beb-f089-440a-88ec-a846ab98a52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LGPInstruction:\n",
    "   \"\"\"\n",
    "   Represents a single instruction in Linear Genetic Programming\n",
    "   \n",
    "   Format: r[dest] = operation(r[src1], r[src2])\n",
    "   \"\"\"\n",
    "   def __init__(self, dest: int, op: str, src1: int, src2: int):\n",
    "       self.dest = dest  # Destination register\n",
    "       self.op = op      # Operation\n",
    "       self.src1 = src1  # Source register 1\n",
    "       self.src2 = src2  # Source register 2\n",
    "       \n",
    "   def __str__(self):\n",
    "       return f\"r[{self.dest}] = r[{self.src1}] {self.op} r[{self.src2}]\"\n",
    "   \n",
    "   def execute(self, registers: np.ndarray) -> np.ndarray:\n",
    "       \"\"\"Execute this instruction on the registers\"\"\"\n",
    "       val1 = registers[self.src1]\n",
    "       val2 = registers[self.src2]\n",
    "       \n",
    "       # Apply the appropriate operation\n",
    "       if self.op == '+':\n",
    "           result = val1 + val2\n",
    "       elif self.op == '-':\n",
    "           result = val1 - val2\n",
    "       elif self.op == '*':\n",
    "           result = val1 * val2\n",
    "       elif self.op == '/':\n",
    "           # Protected division to avoid division by zero\n",
    "           result = val1 / val2 if abs(val2) > 1e-10 else val1\n",
    "       elif self.op == 'sin':\n",
    "           result = np.sin(val1)\n",
    "       elif self.op == 'cos':\n",
    "           result = np.cos(val1)\n",
    "       elif self.op == 'exp':\n",
    "           # Protected exp to avoid overflow\n",
    "           result = np.exp(val1) if val1 < 10 else np.exp(10)\n",
    "       elif self.op == 'log':\n",
    "           # Protected log to handle non-positive inputs\n",
    "           result = np.log(abs(val1)) if abs(val1) > 1e-10 else 0\n",
    "       elif self.op == '<':\n",
    "           result = 1.0 if val1 < val2 else 0.0\n",
    "       elif self.op == '>':\n",
    "           result = 1.0 if val1 > val2 else 0.0\n",
    "       elif self.op == 'min':\n",
    "           result = val2 if val1 > val2 else val1\n",
    "       elif self.op == 'max':\n",
    "           result = val1 if val1 > val2 else val2\n",
    "       else:\n",
    "           raise ValueError(f\"Unknown operation: {self.op}\")\n",
    "       \n",
    "       # Store the result in the destination register\n",
    "       registers[self.dest] = result\n",
    "       return registers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b397256f-efb0-45cf-a7cc-877664d367c1",
   "metadata": {},
   "source": [
    "### 1.2 LGP Program\n",
    "\n",
    "An LGP program consists of a sequence of instructions that operate on a set of registers.\n",
    "The program takes inputs through the first n_inputs registers and returns outputs from the last n_outputs registers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664bdec1-aa36-4c3d-a44c-d82537b539df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LGPProgram:\n",
    "   \"\"\"\n",
    "   Represents a Linear Genetic Programming program\n",
    "   \"\"\"\n",
    "   def __init__(self, instructions: List[LGPInstruction], n_registers: int, \n",
    "               n_inputs: int, n_outputs: int, constants: List[float] = None):\n",
    "       self.instructions = instructions\n",
    "       self.n_registers = n_registers\n",
    "       self.n_inputs = n_inputs\n",
    "       self.n_outputs = n_outputs\n",
    "       self.constants = constants or [0.0, 1.0, -1.0, 0.5, -0.5, 0.1, -0.1, np.pi]\n",
    "       self.fitness = None\n",
    "       \n",
    "   def copy(self):\n",
    "       \"\"\"Create a deep copy of this program\"\"\"\n",
    "       return LGPProgram(\n",
    "           instructions=[copy.deepcopy(i) for i in self.instructions],\n",
    "           n_registers=self.n_registers,\n",
    "           n_inputs=self.n_inputs,\n",
    "           n_outputs=self.n_outputs,\n",
    "           constants=self.constants.copy()\n",
    "       )\n",
    "       \n",
    "   def execute(self, inputs: np.ndarray) -> np.ndarray:\n",
    "       \"\"\"\n",
    "       Execute this program on the given inputs\n",
    "       inputs: Array of shape (n_inputs,)\n",
    "       returns: Array of shape (n_outputs,)\n",
    "       \"\"\"\n",
    "       # Initialize registers\n",
    "       registers = np.zeros(self.n_registers)\n",
    "       \n",
    "       # Set input registers\n",
    "       registers[:self.n_inputs] = inputs\n",
    "       \n",
    "       # Set constant registers\n",
    "       constants_start = self.n_inputs\n",
    "       constants_end = constants_start + len(self.constants)\n",
    "       registers[constants_start:constants_end] = self.constants\n",
    "       \n",
    "       # Execute instructions\n",
    "       for instruction in self.instructions:\n",
    "           registers = instruction.execute(registers)\n",
    "           \n",
    "       # Return output registers\n",
    "       return registers[-self.n_outputs:]\n",
    "   \n",
    "   def __str__(self):\n",
    "       result = f\"LGP Program with {len(self.instructions)} instructions:\\n\"\n",
    "       for i, instruction in enumerate(self.instructions):\n",
    "           result += f\"{i}: {instruction}\\n\"\n",
    "       return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8223e83-5244-4b3f-aaea-005ea061aa2b",
   "metadata": {},
   "source": [
    "## 2. Evolutionary Algorithm Framework\n",
    "\n",
    "The evolutionary algorithm implements the process of evolving LGP programs through selection,\n",
    "crossover, and mutation over multiple generations. The key components include:\n",
    "- Population initialization\n",
    "- Selection mechanisms (tournament and truncation)\n",
    "- Genetic operators (crossover and mutation)\n",
    "- Population evaluation and replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47956b8e-be8d-47b2-9059-e3ebb514eeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LGPEvolution:\n",
    "   \"\"\"\n",
    "   Implements the evolutionary process for Linear Genetic Programming\n",
    "   \"\"\"\n",
    "   def __init__(self, \n",
    "               n_registers: int = 16,\n",
    "               n_inputs: int = 8, \n",
    "               n_outputs: int = 4,\n",
    "               population_size: int = 100,\n",
    "               tournament_size: int = 3,\n",
    "               n_elites: int = 2,\n",
    "               p_crossover: float = 0.9,\n",
    "               p_mutation_instruction: float = 0.2,\n",
    "               p_mutation_dest: float = 0.3,\n",
    "               p_mutation_op: float = 0.2,\n",
    "               p_mutation_src: float = 0.2,\n",
    "               init_min_length: int = 5,\n",
    "               init_max_length: int = 15,\n",
    "               max_length: int = 30,\n",
    "               operations: List[str] = None):\n",
    "       \n",
    "       # Configuration parameters\n",
    "       self.n_registers = n_registers\n",
    "       self.n_inputs = n_inputs\n",
    "       self.n_outputs = n_outputs\n",
    "       self.population_size = population_size\n",
    "       self.tournament_size = tournament_size\n",
    "       self.n_elites = n_elites\n",
    "       self.p_crossover = p_crossover\n",
    "       self.p_mutation_instruction = p_mutation_instruction\n",
    "       self.p_mutation_dest = p_mutation_dest\n",
    "       self.p_mutation_op = p_mutation_op\n",
    "       self.p_mutation_src = p_mutation_src\n",
    "       self.init_min_length = init_min_length\n",
    "       self.init_max_length = init_max_length\n",
    "       self.max_length = max_length\n",
    "       self.operations = operations or ['+', '-', '*', '/', 'sin', 'cos', '<', '>', 'min', 'max']\n",
    "       \n",
    "       # Initialize population\n",
    "       self.population = self.initialize_population()\n",
    "       self.best_individual = None\n",
    "       self.best_fitness = float(\"-inf\")\n",
    "       self.fitness_history = []\n",
    "       \n",
    "   # ### 2.1 Population Initialization\n",
    "   #\n",
    "   # We start by creating a diverse population of random LGP programs with varying lengths.\n",
    "   \n",
    "   def initialize_population(self) -> List[LGPProgram]:\n",
    "       \"\"\"Initialize a random population of LGP programs\"\"\"\n",
    "       population = []\n",
    "       \n",
    "       for _ in range(self.population_size):\n",
    "           # Determine program length\n",
    "           length = random.randint(self.init_min_length, self.init_max_length)\n",
    "           \n",
    "           # Generate random instructions\n",
    "           instructions = []\n",
    "           for _ in range(length):\n",
    "               # For outputs, we only want to write to output registers\n",
    "               dest = random.randint(self.n_inputs, self.n_registers - 1)\n",
    "               op = random.choice(self.operations)\n",
    "               src1 = random.randint(0, self.n_registers - 1)\n",
    "               src2 = random.randint(0, self.n_registers - 1)\n",
    "               \n",
    "               instructions.append(LGPInstruction(dest, op, src1, src2))\n",
    "           \n",
    "           # Create program\n",
    "           program = LGPProgram(\n",
    "               instructions=instructions,\n",
    "               n_registers=self.n_registers,\n",
    "               n_inputs=self.n_inputs,\n",
    "               n_outputs=self.n_outputs\n",
    "           )\n",
    "           \n",
    "           population.append(program)\n",
    "           \n",
    "       return population\n",
    "   \n",
    "   # ### 2.2 Selection Mechanisms\n",
    "   #\n",
    "   # We implement two selection methods:\n",
    "   # - Truncation selection: Selects the top N individuals based on fitness\n",
    "   # - Tournament selection: Randomly selects k individuals and returns the best one\n",
    "   \n",
    "   def truncation_selection(self, population: List[LGPProgram], n: int) -> List[LGPProgram]:\n",
    "       \"\"\"Select the n best individuals from the population using truncation selection.\"\"\"\n",
    "       # Sort population by fitness (in descending order)\n",
    "       sorted_population = sorted(\n",
    "           population, \n",
    "           key=lambda ind: ind.fitness if ind.fitness is not None else float(\"-inf\"),\n",
    "           reverse=True\n",
    "       )\n",
    "       \n",
    "       # Select the top n individuals\n",
    "       selected = sorted_population[:n]\n",
    "       \n",
    "       return selected\n",
    "\n",
    "   def tournament_selection(self, population: List[LGPProgram]) -> LGPProgram:\n",
    "       \"\"\"Select an individual using tournament selection\"\"\"\n",
    "       # Randomly select tournament_size individuals\n",
    "       tournament = random.sample(population, self.tournament_size)\n",
    "       \n",
    "       # Return the best individual in the tournament\n",
    "       return max(tournament, key=lambda p: p.fitness if p.fitness is not None else float(\"-inf\"))\n",
    "   \n",
    "   # ### 2.3 Genetic Operators\n",
    "   #\n",
    "   # We implement two main genetic operators:\n",
    "   # - Crossover: Exchanges instruction segments between two parent programs\n",
    "   # - Mutation: Modifies instruction components or adds/removes/swaps instructions\n",
    "   \n",
    "   def crossover(self, parent1: LGPProgram, parent2: LGPProgram) -> Tuple[LGPProgram, LGPProgram]:\n",
    "       \"\"\"Perform crossover between two parent programs\"\"\"\n",
    "       if random.random() > self.p_crossover or len(parent1.instructions) < 2 or len(parent2.instructions) < 2:\n",
    "           # No crossover\n",
    "           return parent1.copy(), parent2.copy()\n",
    "       \n",
    "       # One-point crossover\n",
    "       child1 = parent1.copy()\n",
    "       child2 = parent2.copy()\n",
    "       \n",
    "       # Select crossover points\n",
    "       point1 = random.randint(1, len(parent1.instructions) - 1)\n",
    "       point2 = random.randint(1, len(parent2.instructions) - 1)\n",
    "       \n",
    "       # Swap instructions\n",
    "       temp1 = child1.instructions[point1:]\n",
    "       temp2 = child2.instructions[point2:]\n",
    "       \n",
    "       child1.instructions = child1.instructions[:point1] + temp2\n",
    "       child2.instructions = child2.instructions[:point2] + temp1\n",
    "       \n",
    "       # Ensure length constraints\n",
    "       if len(child1.instructions) > self.max_length:\n",
    "           child1.instructions = child1.instructions[:self.max_length]\n",
    "       if len(child2.instructions) > self.max_length:\n",
    "           child2.instructions = child2.instructions[:self.max_length]\n",
    "           \n",
    "       return child1, child2\n",
    "   \n",
    "   def mutate(self, program: LGPProgram) -> LGPProgram:\n",
    "       \"\"\"Mutate a program\"\"\"\n",
    "       mutated = program.copy()\n",
    "       \n",
    "       # 1. Mutate instructions\n",
    "       if random.random() < self.p_mutation_instruction and len(mutated.instructions) > 0:\n",
    "           # Randomly choose to add, remove, or swap an instruction\n",
    "           mutation_type = random.choice(['add', 'remove', 'swap'])\n",
    "           \n",
    "           if mutation_type == 'add' and len(mutated.instructions) < self.max_length:\n",
    "               # Add a new random instruction\n",
    "               dest = random.randint(self.n_inputs, self.n_registers - 1)\n",
    "               op = random.choice(self.operations)\n",
    "               src1 = random.randint(0, self.n_registers - 1)\n",
    "               src2 = random.randint(0, self.n_registers - 1)\n",
    "               \n",
    "               new_instruction = LGPInstruction(dest, op, src1, src2)\n",
    "               insert_pos = random.randint(0, len(mutated.instructions))\n",
    "               mutated.instructions.insert(insert_pos, new_instruction)\n",
    "               \n",
    "           elif mutation_type == 'remove' and len(mutated.instructions) > 1:\n",
    "               # Remove a random instruction\n",
    "               remove_pos = random.randint(0, len(mutated.instructions) - 1)\n",
    "               mutated.instructions.pop(remove_pos)\n",
    "               \n",
    "           elif mutation_type == 'swap' and len(mutated.instructions) > 1:\n",
    "               # Swap two random instructions\n",
    "               pos1 = random.randint(0, len(mutated.instructions) - 1)\n",
    "               pos2 = random.randint(0, len(mutated.instructions) - 1)\n",
    "               mutated.instructions[pos1], mutated.instructions[pos2] = mutated.instructions[pos2], mutated.instructions[pos1]\n",
    "       \n",
    "       # 2. Mutate instruction components\n",
    "       for instruction in mutated.instructions:\n",
    "           # Mutate destination register\n",
    "           if random.random() < self.p_mutation_dest:\n",
    "               instruction.dest = random.randint(self.n_inputs, self.n_registers - 1)\n",
    "               \n",
    "           # Mutate operation\n",
    "           if random.random() < self.p_mutation_op:\n",
    "               instruction.op = random.choice(self.operations)\n",
    "               \n",
    "           # Mutate source registers\n",
    "           if random.random() < self.p_mutation_src:\n",
    "               instruction.src1 = random.randint(0, self.n_registers - 1)\n",
    "           if random.random() < self.p_mutation_src:\n",
    "               instruction.src2 = random.randint(0, self.n_registers - 1)\n",
    "               \n",
    "       return mutated\n",
    "   \n",
    "   # ### 2.4 Population Evaluation and Evolution\n",
    "   #\n",
    "   # We evaluate the population and evolve it over multiple generations.\n",
    "   \n",
    "   def evaluate_population(self, eval_func: Callable[[LGPProgram], float]) -> None:\n",
    "       \"\"\"Evaluate all individuals in the population\"\"\"\n",
    "       for individual in self.population:\n",
    "           individual.fitness = eval_func(individual)\n",
    "           \n",
    "           # Update best individual\n",
    "           if individual.fitness > self.best_fitness:\n",
    "               self.best_fitness = individual.fitness\n",
    "               self.best_individual = individual.copy()\n",
    "   \n",
    "   def evolve(self, eval_func: Callable[[LGPProgram], float], \n",
    "             n_generations: int = 100, verbose: bool = True) -> LGPProgram:\n",
    "       \"\"\"Run the evolutionary process\"\"\"\n",
    "       # Initial evaluation\n",
    "       self.evaluate_population(eval_func)\n",
    "       self.fitness_history.append(self.best_fitness)\n",
    "       \n",
    "       if verbose:\n",
    "           print(f\"Generation 0: Best fitness = {self.best_fitness:.4f}\")\n",
    "       \n",
    "       for generation in range(1, n_generations + 1):\n",
    "           # Create new population with elitism (keeping best individuals)\n",
    "           new_population = self.truncation_selection(self.population, self.n_elites)\n",
    "           \n",
    "           # Fill the rest of the population with offspring from crossover and mutation\n",
    "           while len(new_population) < self.population_size:\n",
    "               # Select parents\n",
    "               parent1 = self.tournament_selection(self.population)\n",
    "               parent2 = self.tournament_selection(self.population)\n",
    "               \n",
    "               # Crossover\n",
    "               child1, child2 = self.crossover(parent1, parent2)\n",
    "               \n",
    "               # Mutation\n",
    "               child1 = self.mutate(child1)\n",
    "               child2 = self.mutate(child2)\n",
    "               \n",
    "               # Add to new population\n",
    "               new_population.append(child1)\n",
    "               new_population.append(child2)\n",
    "           \n",
    "           # Truncate if necessary\n",
    "           if len(new_population) > self.population_size:\n",
    "               new_population = new_population[:self.population_size]\n",
    "           \n",
    "           # Replace population\n",
    "           self.population = new_population\n",
    "           \n",
    "           # Evaluate new population\n",
    "           self.evaluate_population(eval_func)\n",
    "           self.fitness_history.append(self.best_fitness)\n",
    "           \n",
    "           if verbose and generation % 10 == 0:\n",
    "               print(f\"Generation {generation}: Best fitness = {self.best_fitness:.4f}\")\n",
    "       \n",
    "       return self.best_individual"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a57187-218d-4667-b4a5-40ec95c3863d",
   "metadata": {},
   "source": [
    "## 3. Environment Interaction and Evaluation\n",
    "\n",
    "We'll use OpenAI Gym's LunarLander environment to evaluate our LGP programs.\n",
    "This environment requires the agent to learn how to land a lunar module safely on a landing pad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96453965-445a-4e81-ab0f-dc196df05069",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LunarLanderLGP:\n",
    "   def __init__(self, episodes_per_eval: int = 5, max_steps: int = 1000):\n",
    "       self.env = gym.make('LunarLander-v3')\n",
    "       self.episodes_per_eval = episodes_per_eval\n",
    "       self.max_steps = max_steps\n",
    "       \n",
    "   def evaluate_program(self, program: LGPProgram) -> float:\n",
    "       \"\"\"Evaluate an LGP program on the LunarLander environment\"\"\"\n",
    "       total_reward = 0\n",
    "       \n",
    "       for _ in range(self.episodes_per_eval):\n",
    "           observation, info = self.env.reset(seed=random.randint(0, 10000))\n",
    "           episode_reward = 0\n",
    "           \n",
    "           for step in range(self.max_steps):\n",
    "               # Get action from program\n",
    "               action_values = program.execute(observation)\n",
    "               action = np.argmax(action_values)  # Choose action with highest value\n",
    "               \n",
    "               # Take action in environment\n",
    "               observation, reward, terminated, truncated, info = self.env.step(action)\n",
    "               episode_reward += reward\n",
    "               \n",
    "               if terminated or truncated:\n",
    "                   break\n",
    "           \n",
    "           total_reward += episode_reward\n",
    "       \n",
    "       avg_reward = total_reward / self.episodes_per_eval\n",
    "       return avg_reward\n",
    "   \n",
    "   def render_best_program(self, program: LGPProgram, n_episodes: int = 3) -> None:\n",
    "       \"\"\"Render the best program's performance\"\"\"\n",
    "       for episode in range(n_episodes):\n",
    "           env_render = gym.make('LunarLander-v3', render_mode='human')\n",
    "           observation, info = env_render.reset(seed=episode)\n",
    "           episode_reward = 0\n",
    "           \n",
    "           for step in range(self.max_steps):\n",
    "               # Get action from program\n",
    "               action_values = program.execute(observation)\n",
    "               action = np.argmax(action_values)\n",
    "               \n",
    "               # Take action in environment\n",
    "               observation, reward, terminated, truncated, info = env_render.step(action)\n",
    "               episode_reward += reward\n",
    "               \n",
    "               if terminated or truncated:\n",
    "                   break\n",
    "           \n",
    "           print(f\"Episode {episode+1} Reward: {episode_reward:.2f}\")\n",
    "           env_render.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658c2b14-a126-47eb-b879-72344b745a5b",
   "metadata": {},
   "source": [
    "## 4. Running the Evolution and Visualizing Results\n",
    "\n",
    "Now we can run the evolution process and visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855c758b-0647-4c4b-b513-bdc27b67cb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_lgp_evolution():\n",
    "   # Initialize LunarLander environment for LGP\n",
    "   lunar_lander = LunarLanderLGP(episodes_per_eval=3, max_steps=1000)\n",
    "   \n",
    "   # Configure LGP evolution\n",
    "   lgp_evolution = LGPEvolution(\n",
    "       n_registers=20,               # Number of registers\n",
    "       n_inputs=8,                   # LunarLander has 8 inputs\n",
    "       n_outputs=4,                  # LunarLander has 4 actions\n",
    "       population_size=30,\n",
    "       tournament_size=3,\n",
    "       n_elites=5,                   # Number of elite individuals to keep\n",
    "       p_crossover=0.6,\n",
    "       p_mutation_instruction=0.2,\n",
    "       p_mutation_dest=0.5,\n",
    "       p_mutation_op=0.5,\n",
    "       p_mutation_src=0.5,\n",
    "       init_min_length=8,\n",
    "       init_max_length=20,\n",
    "       max_length=30,\n",
    "       operations=['+', '-', '*', '/', 'sin', 'cos', '<', '>', 'min', 'max']\n",
    "   )\n",
    "   \n",
    "   # Evolution process\n",
    "   print(\"Starting LGP Evolution for LunarLander...\")\n",
    "   start_time = time.time()\n",
    "   \n",
    "   best_program = lgp_evolution.evolve(\n",
    "       eval_func=lunar_lander.evaluate_program,\n",
    "       n_generations=50,\n",
    "       verbose=True\n",
    "   )\n",
    "   \n",
    "   end_time = time.time()\n",
    "   elapsed_time = end_time - start_time\n",
    "   \n",
    "   print(f\"\\nEvolution completed in {elapsed_time:.2f} seconds\")\n",
    "   print(\"\\nBest program:\")\n",
    "   print(best_program)\n",
    "   \n",
    "   # Plot fitness history\n",
    "   plt.figure(figsize=(10, 6))\n",
    "   plt.plot(lgp_evolution.fitness_history)\n",
    "   plt.title('LGP Evolution Fitness History')\n",
    "   plt.xlabel('Generation')\n",
    "   plt.ylabel('Fitness (Average Reward)')\n",
    "   plt.grid(True)\n",
    "   plt.savefig('lgp_fitness_history.png')\n",
    "   plt.show()\n",
    "   \n",
    "   # Visualize best program\n",
    "   print(\"\\nRendering best program performance...\")\n",
    "   lunar_lander.render_best_program(best_program, n_episodes=3)\n",
    "   \n",
    "   return best_program, lgp_evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c131b2-c8ac-4a35-aacb-2e5b6d4267d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_program, lgp_evolution = run_lgp_evolution()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168bd244-4f98-481f-b1c5-64fee736ed0f",
   "metadata": {},
   "source": [
    "## 5. Exercise: Extending to Quality-Diversity Optimization\n",
    "\n",
    "Our current implementation focuses only on finding a single high-performing solution.\n",
    "However, the search gets stuck at local optima, limiting the result. Quality-Diversity Optimization can help explore new behaviors, leading to better policies in the end.\n",
    "\n",
    "The pyribs library provides tools for Quality-Diversity Optimization, including the \n",
    "MAP-Elites algorithm and its variants.\n",
    "\n",
    "For an exercise, try extending this implementation to use Quality-Diversity Optimization.\n",
    "Here's a sketch of how you might start if you use pyribs. Another option is to modify the above code, adding a Novelty fitness term to encourage exploration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051c5b82-1aa8-411d-bcea-1452e87c9d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ribs\n",
    "from ribs.archives import GridArchive\n",
    "from ribs.emitters import GeneticAlgorithmEmitter\n",
    "from ribs.schedulers import Scheduler\n",
    "\n",
    "# Define behavior descriptors for LunarLander\n",
    "# e.g., landing speed and fuel consumption\n",
    "\n",
    "# Create archive\n",
    "archive = GridArchive(\n",
    "    solution_dim=...,  # Dimension of solution\n",
    "    dims=[10, 10],     # Number of bins for each behavior descriptor\n",
    "    ranges=[[-5, 5], [0, 100]],  # Ranges for each behavior descriptor\n",
    ")\n",
    "\n",
    "# Create emitter\n",
    "emitter = GeneticAlgorithmEmitter(\n",
    "    archive=archive,\n",
    "    x0=initial_solution,\n",
    "    batch_size=population_size,\n",
    "    ...\n",
    ")\n",
    "\n",
    "# Create scheduler\n",
    "scheduler = Scheduler([emitter])\n",
    "\n",
    "# Run optimization\n",
    "for _ in range(iterations):\n",
    "    solutions = scheduler.ask()\n",
    "    \n",
    "    # Evaluate solutions and collect behavior descriptors\n",
    "    objectives = []\n",
    "    behaviors = []\n",
    "    \n",
    "    for solution in solutions:\n",
    "        # Convert solution to LGP program\n",
    "        program = solution_to_program(solution)\n",
    "        \n",
    "        # Evaluate program\n",
    "        objective, behavior = evaluate_program_with_behavior(program)\n",
    "        \n",
    "        objectives.append(objective)\n",
    "        behaviors.append(behavior)\n",
    "    \n",
    "    # Tell scheduler results\n",
    "    scheduler.tell(objectives, behaviors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
